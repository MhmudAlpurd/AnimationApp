{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hwrs002.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO6AdLvdlB21g/dzSxIiYsU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MhmudAlpurd/AnimationApp/blob/master/hwrs002.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBjCwuk7Ckhj",
        "outputId": "c2283c7e-a047-4dd7-d4b5-3690535f4266"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZ7KbjcJC2UK",
        "outputId": "c4c6090f-a737-430f-976f-2ae83d6d31e6"
      },
      "source": [
        "cd /content/drive/My Drive/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssKnWPrsCVg4"
      },
      "source": [
        "import os, cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import random as rnd\n",
        "from tqdm import tqdm\n",
        "import pickle as pkl\n",
        "import PIL"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3TD6Yt2FW-K"
      },
      "source": [
        "**#path creation**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13F67kcgC915"
      },
      "source": [
        "DIRECTORY = 'Hampalai/HWRS_0_0_2/'\n",
        "CATEGORIES = ['plastics', 'metal' , 'paper' , 'glass']\n",
        "img_lbl_arr = []\n",
        "IMAGE_SIZE = 224"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXv_MCkUD33Z",
        "outputId": "b7416527-14e1-480a-9ff0-118d449d8cb1"
      },
      "source": [
        "for category in tqdm(CATEGORIES):\n",
        "    category_folder = os.path.join(DIRECTORY, category)\n",
        "    img_label = CATEGORIES.index(category)\n",
        "    for img in os.listdir(category_folder):\n",
        "        image_path = os.path.join(category_folder, img)\n",
        "        #img_read = mpimg.imread(image_path)\n",
        "        #imgplot = plt.imshow(img_read)\n",
        "        #plt.show()\n",
        "        img_loaded_r = cv2.imread(image_path)\n",
        "        img_loaded = cv2.resize(img_loaded_r, (IMAGE_SIZE,IMAGE_SIZE))\n",
        "        img_lbl_arr.append([img_loaded, img_label])\n",
        "\n",
        "print(len(img_lbl_arr))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:12<00:00,  3.16s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZN1WDzjEvfg"
      },
      "source": [
        "**#shuffle the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVRgYpodEoXC"
      },
      "source": [
        "rnd.shuffle(img_lbl_arr)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaKUdeBuE9xx"
      },
      "source": [
        "**#split image and labels and convert lst to arr**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xox8OWY9FAxh",
        "outputId": "024e4c88-81ef-4120-c35a-5a3d35356d02"
      },
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for img_tensor, labels in img_lbl_arr:\n",
        "    X.append(img_tensor) #X = image tensor\n",
        "    y.append(labels) #y = label list\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "#pkl.dump(X, open('X.pkl', 'wb'))\n",
        "#pkl.dump(y, open('y.pkl', 'wb'))\n",
        "\n",
        "#X = pkl.load(open('X.pkl', 'rb'))\n",
        "#y = pkl.load(open('y.pkl', 'rb'))\n",
        "\n",
        "print(X.shape)\n",
        "#(1987, 150, 150, 3)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1987, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVjKreTOm-hF",
        "outputId": "6a32d5f4-c505-4435-ab8a-726853d0e104"
      },
      "source": [
        "from sklearn.model_selection import  train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "img_train, img_test, lbl_train, lbl_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
        "print('img_train:', len(img_train), type(img_train[0]), '| img_test:', len(img_test), '| lbl_train:', len(lbl_train), type(lbl_train[0]) , '| lbl_test:', len(lbl_test))\n",
        "\n",
        "# convert the labels from integers to vectors\n",
        "lbl_train = to_categorical(lbl_train, num_classes=4)\n",
        "lbl_test = to_categorical(lbl_test, num_classes=4)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "img_train: 1589 <class 'numpy.ndarray'> | img_test: 398 | lbl_train: 1589 <class 'numpy.int64'> | lbl_test: 398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHvdFEKOGRVB"
      },
      "source": [
        "**#ImageDataGenerator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJPmcTF-FE5Z"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    featurewise_center=True, samplewise_center=True,\n",
        "    featurewise_std_normalization=True, samplewise_std_normalization=True,\n",
        "    rotation_range=20, width_shift_range=0.2,\n",
        "    height_shift_range=0.2, shear_range=0.1, zoom_range=0.2,\n",
        "    channel_shift_range=0.2, fill_mode='nearest', cval=0.1, horizontal_flip=True,\n",
        "    vertical_flip=True , rescale=True\n",
        "\n",
        ")\n",
        "\n",
        "datagen.fit(img_train)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H92e8wZ2HXNb"
      },
      "source": [
        "**#model creation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "vxcd_s8EzwZM",
        "outputId": "c8bbbab7-d820-4184-a34e-c31747fc9331"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "\n",
        "optimizer_1 = SGD(lr=1e-4, momentum=0.99)\n",
        "optimizer_2 = Adam(lr=1e-3)\n",
        "\n",
        "base_model = VGG16(include_top= False, weights='imagenet', input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
        "\n",
        "myModel = Sequential()\n",
        "myModel.add(base_model)\n",
        "myModel.add(Dropout(0.5))\n",
        "myModel.add(Dense(4, activation='softmax'))\n",
        "myModel.summary()\n",
        "\n",
        "myModel.compile(loss = 'binary_crossentropy', optimizer= optimizer_2, metrics=['accuracy'])\n",
        "myModel.fit(x=datagen.flow(img_train, lbl_train, batch_size=32),validation_data=(img_test, lbl_test), steps_per_epoch=100,epochs=100, verbose=2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6f48b4830753>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0moptimizer_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmyModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'IMAGE_SIZE' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FA1p_bZhP8S",
        "outputId": "f8b81f68-40b9-4d1a-d14f-772e68a0e10d"
      },
      "source": [
        "input_layer = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same')(input_layer)\n",
        "pool1 = MaxPooling2D(pool_size = 2)(conv1)\n",
        "conv2 = Conv2D(32, 3, activation = 'relu', padding = 'same')(pool1)\n",
        "pool2 = MaxPooling2D(pool_size=2)(conv2)\n",
        "flat = Flatten()(pool2)\n",
        "out_layer = Dense(4, activation = 'softmax')(flat)\n",
        "myModel = Model(input_layer, out_layer)\n",
        "myModel.summary()\n",
        "\n",
        "#------------------\n",
        "base_model = VGG16(include_top= True, weights='imagenet', input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
        "input_layer = Input(base_model)\n",
        "\n",
        "#input_layer = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same')(input_layer)\n",
        "pool1 = MaxPooling2D(pool_size = 2)(conv1)\n",
        "conv2 = Conv2D(32, 3, activation = 'relu', padding = 'same')(pool1)\n",
        "pool2 = MaxPooling2D(pool_size=2)(conv2)\n",
        "flat = Flatten()(pool2)\n",
        "out_layer = Dense(4, activation = 'softmax')(flat)\n",
        "myModel = Model(input_layer, out_layer)\n",
        "myModel.summary()\n",
        "\n",
        "\n",
        "#myModel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
        "#myModel.compile(loss=\"binary_crossentropy\", optimizer='Adam', metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "myModel.fit(x=datagen.flow(img_train, lbl_train, batch_size=32),validation_data=(img_test, lbl_test), steps_per_epoch=len(img_train) // 32,epochs=3, verbose=1)\n",
        "myModel.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 112, 112, 32)      18464     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 56, 56, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 100352)            0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4)                 401412    \n",
            "=================================================================\n",
            "Total params: 421,668\n",
            "Trainable params: 421,668\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHYxECODxt8s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFRPPKZwHnzB"
      },
      "source": [
        "from keras.optimizers import SGD, Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "optimizer_1 = SGD(lr=1e-4, momentum=0.99)\n",
        "optimizer_2 = Adam(lr=1e-3)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer_1, metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wWfExIOsqo-"
      },
      "source": [
        "EPOCHS = 100\n",
        "BS = 32\n",
        "# construct the training image generator for data augmentation\n",
        "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
        "\twidth_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
        "\thorizontal_flip=True, fill_mode=\"nearest\")\n",
        "# train the network\n",
        "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n",
        "\tvalidation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,\n",
        "\tepochs=EPOCHS)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzQwirc_l0S6"
      },
      "source": [
        "#https://www.pyimagesearch.com/2018/12/24/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial/\n",
        "#The Keras deep learning libraries to train model:\n",
        "#1.fit\n",
        "#2.fit_generator\n",
        "#3.train_on_batch\n",
        "\n",
        "EPOCHS = 100\n",
        "BS = 128\n",
        "\n",
        "trained_model = myModel.fit(X, y ,batch_size= BS, epochs= EPOCHS,verbose=2, validation_split= 0.2, validation_data =(img_test, lbl_test) , validation_steps = 100,steps_per_epoch=100, shuffle=True)\n",
        "\n",
        "#history = myModel.fit(\n",
        "   # image_gen.flow(img_train, lbl_train, batch_size=BS, shuffle= True),\n",
        "   # validation_data =(img_test, lbl_test),\n",
        "    #validation_steps = 100,\n",
        "    #steps_per_epoch =  (len(img_train) // BS ),\n",
        "   # epochs = EPOCHS,\n",
        "    #verbose= 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wVwqXU2HfMJ"
      },
      "source": [
        "**#Fitting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCRe6yH7FTQC"
      },
      "source": [
        "input_layer = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same')(input_layer)\n",
        "pool1 = MaxPooling2D(pool_size = 2)(conv1)\n",
        "conv2 = Conv2D(32, 3, activation = 'relu', padding = 'same')(pool1)\n",
        "pool2 = MaxPooling2D(pool_size=2)(conv2)\n",
        "flat = Flatten()(pool2)\n",
        "out_layer = Dense(4, activation = 'softmax')(flat)\n",
        "myModel = Model(input_layer, out_layer)\n",
        "myModel.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zD2IPNZeHjlJ"
      },
      "source": [
        "**#Prediction**"
      ]
    }
  ]
}